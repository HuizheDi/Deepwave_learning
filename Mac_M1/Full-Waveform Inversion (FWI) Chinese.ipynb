{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f718486-aa66-41f6-aec6-6dbf431ba1f3",
   "metadata": {},
   "source": [
    "全波形反演为匹配整个记录数据集(包括折射波)的模型提供了反演的潜力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794094e-d5cf-4aff-8e93-2c06ac3ecf55",
   "metadata": {},
   "source": [
    "我们继续使用Marmousi模型，但由于运行多次FWI需要更大的计算成本，这里，我们将只研究其中的一部分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d3dda-4a32-47de-a527-bd1f6f432f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchaudio.functional import biquad\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import butter\n",
    "import matplotlib.pyplot as plt\n",
    "import deepwave\n",
    "from deepwave import scalar\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available()\n",
    "                      else 'cpu')\n",
    "ny = 2301\n",
    "nx = 751\n",
    "dx = 4.0\n",
    "v_true = torch.from_file('marmousi_vp.bin',\n",
    "                         size=ny*nx).reshape(ny, nx)\n",
    "\n",
    "# Select portion of model for inversion\n",
    "ny = 600\n",
    "nx = 250\n",
    "v_true = v_true[:ny, :nx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8750606-c795-46c2-88a2-9087f3df8679",
   "metadata": {},
   "source": [
    "我们对真实模型进行平滑来创建初始速度模型，并尝试通过反演来改进它。使用上一个例子中的合成数据为观测数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcaeb4-9d4f-4ea2-b420-3de18fd4610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_init = (torch.tensor(1/gaussian_filter(1/v_true.numpy(), 40))\n",
    "          .to(device))\n",
    "v = v_init.clone()\n",
    "v.requires_grad_()\n",
    "\n",
    "n_shots = 115\n",
    "\n",
    "n_sources_per_shot = 1\n",
    "d_source = 20  # 20 * 4m = 80m\n",
    "first_source = 10  # 10 * 4m = 40m\n",
    "source_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "n_receivers_per_shot = 384\n",
    "d_receiver = 6  # 6 * 4m = 24m\n",
    "first_receiver = 0  # 0 * 4m = 0m\n",
    "receiver_depth = 2  # 2 * 4m = 8m\n",
    "\n",
    "freq = 25\n",
    "nt = 750\n",
    "dt = 0.004\n",
    "peak_time = 1.5 / freq\n",
    "\n",
    "observed_data = (\n",
    "    torch.from_file('marmousi_data.bin',\n",
    "                    size=n_shots*n_receivers_per_shot*nt)\n",
    "    .reshape(n_shots, n_receivers_per_shot, nt)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0ec95-005a-4845-b062-b9a44d4f6972",
   "metadata": {},
   "source": [
    "由于我们的模型现在更小了，我们也只需要提取覆盖模型这一部分的观测数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5839e-e7d1-4092-a0c4-f7204ef8b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 20\n",
    "n_receivers_per_shot = 100\n",
    "nt = 300\n",
    "observed_data = (\n",
    "    observed_data[:n_shots, :n_receivers_per_shot, :nt].to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638348cb-f161-4cc9-b933-47682ee3ef6d",
   "metadata": {},
   "source": [
    "我们像之前一样设置震源和接收器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41422417-1141-4bf9-8977-2724b0b1ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_locations\n",
    "source_locations = torch.zeros(n_shots, n_sources_per_shot, 2,\n",
    "                               dtype=torch.long, device=device)\n",
    "source_locations[..., 1] = source_depth\n",
    "source_locations[:, 0, 0] = (torch.arange(n_shots) * d_source +\n",
    "                             first_source)\n",
    "\n",
    "# receiver_locations\n",
    "receiver_locations = torch.zeros(n_shots, n_receivers_per_shot, 2,\n",
    "                                 dtype=torch.long, device=device)\n",
    "receiver_locations[..., 1] = receiver_depth\n",
    "receiver_locations[:, :, 0] = (\n",
    "    (torch.arange(n_receivers_per_shot) * d_receiver +\n",
    "     first_receiver)\n",
    "    .repeat(n_shots, 1)\n",
    ")\n",
    "\n",
    "# source_amplitudes\n",
    "source_amplitudes = (\n",
    "    (deepwave.wavelets.ricker(freq, nt, dt, peak_time))\n",
    "    .repeat(n_shots, n_sources_per_shot, 1).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ef41f-1fad-4bca-ba61-cefc507b7313",
   "metadata": {},
   "source": [
    "现在我们准备运行优化器来执行波速模型的迭代反演。这将使用与PyTorch中用于训练典型神经网络非常相似的代码来实现。唯一值得注意的区别是，我们使用更大的学习率(1e9)将梯度值提升到一个范围，这将有助于我们在每次迭代中取得良好的进展，并且我们对梯度应用剪辑(到其大小的第98个百分位数)，以避免在少数点(例如源周围)进行非常大的更改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b27c49-a288-4bf5-8f3f-dea6f5c215a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimiser to perform inversion\n",
    "optimiser = torch.optim.SGD([v], lr=1e9, momentum=0.9)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Run optimisation/inversion\n",
    "n_epochs = 250\n",
    "v_true = v_true.to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    out = scalar(\n",
    "        v, dx, dt,\n",
    "        source_amplitudes=source_amplitudes,\n",
    "        source_locations=source_locations,\n",
    "        receiver_locations=receiver_locations,\n",
    "        pml_freq=freq,\n",
    "    )\n",
    "    loss = loss_fn(out[-1], observed_data)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(\n",
    "        v,\n",
    "        torch.quantile(v.grad.detach().abs(), 0.98)\n",
    "    )\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867bb18-57c2-4324-913f-986bfd88805f",
   "metadata": {},
   "source": [
    "结果提高了我们对波速模型的估计精度。请注意，源没有覆盖右侧表面的一部分，这就是为什么那里的结果更差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c676764-cc48-4c0a-94fa-faab8b574930",
   "metadata": {},
   "source": [
    "然而，看起来低波数信息(层速度)在模型的较低部分丢失了。这可能是由于通常影响地震反演的周期跳变问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993d1c2-2c89-407e-ae18-f97d3c9fd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "vmin = v_true.min()\n",
    "vmax = v_true.max()\n",
    "_, ax = plt.subplots(3, figsize=(10.5, 10.5), sharex=True,\n",
    "                     sharey=True)\n",
    "ax[0].imshow(v_init.cpu().T, aspect='auto', cmap='jet',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Initial\")\n",
    "ax[1].imshow(v.detach().cpu().T, aspect='auto', cmap='jet',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Out\")\n",
    "ax[2].imshow(v_true.cpu().T, aspect='auto', cmap='jet',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('example_simple_fwi.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3fc73-4d95-4b1a-801e-56d651321e43",
   "metadata": {},
   "source": [
    "这样我们就遇到了两个问题。首先是在逆温过程中，特定单元的速度值变得太大或太小的风险，并引起稳定性问题，这是由源和接收器附近的梯度值很大引起的，因此优化器在那里采取了很大的步骤。我们试图通过使用渐变剪辑来解决这个问题。第二个问题是周期跳变，即模型的到达点与目标对应点之间的偏移超过半个波长，这可能导致反演陷入局部最小值。让我们尝试通过对代码进行一些改进来克服这些问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412956c-0976-418b-9d52-660fc19ac6ab",
   "metadata": {},
   "source": [
    "解决速度极值问题的一种方法是将速度限制在期望的范围内。因为PyTorch允许我们将运算符链在一起，并且会自动通过它们反向传播来计算梯度，所以我们可以使用函数来生成速度模型。这为我们提供了一种方便而稳健的方法来约束模型中的速度范围。我们可以将我们的速度模型定义为一个包含与我们的模型大小相同的张量的物体。当我们调用这个对象的forward方法时，它返回对这个存储张量应用sigmoid操作的输出，结果是每个单元格的值在0到1之间，然后将其缩放到我们想要的范围。我们可以使用logit算子将它的初始输出设置为我们选择的初始速度模型，它是sigmoid的逆:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613ab5d-a725-46c3-8989-1a7fa6c2c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second attempt: constrained velocity and frequency filtering\n",
    "\n",
    "\n",
    "# Define a function to taper the ends of traces\n",
    "def taper(x):\n",
    "    return deepwave.common.cosine_taper_end(x, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ee575-8fb5-46db-ac5f-5bf631a6fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a velocity model constrained to be within a desired range\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, initial, min_vel, max_vel):\n",
    "        super().__init__()\n",
    "        self.min_vel = min_vel\n",
    "        self.max_vel = max_vel\n",
    "        self.model = torch.nn.Parameter(\n",
    "            torch.logit((initial - min_vel) /\n",
    "                        (max_vel - min_vel))\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        return (torch.sigmoid(self.model) *\n",
    "                (self.max_vel - self.min_vel) +\n",
    "                self.min_vel)\n",
    "\n",
    "\n",
    "observed_data = taper(observed_data)\n",
    "model = Model(v_init, 1000, 2500).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90064485-f5fb-4f24-b6bf-9cc325eb6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimisation/inversion\n",
    "n_epochs = 2\n",
    "\n",
    "for cutoff_freq in [10, 15, 20, 25, 30]:\n",
    "    sos = butter(6, cutoff_freq, fs=1/dt, output='sos')\n",
    "    sos = [torch.tensor(sosi).to(observed_data.dtype).to(device)\n",
    "           for sosi in sos]\n",
    "\n",
    "    def filt(x):\n",
    "        return biquad(biquad(biquad(x, *sos[0]), *sos[1]), *sos[2])\n",
    "    observed_data_filt = filt(observed_data)\n",
    "    optimiser = torch.optim.LBFGS(model.parameters(),\n",
    "                                  line_search_fn='strong_wolfe')\n",
    "    for epoch in range(n_epochs):\n",
    "        def closure():\n",
    "            optimiser.zero_grad()\n",
    "            v = model()\n",
    "            out = scalar(\n",
    "                v, dx, dt,\n",
    "                source_amplitudes=source_amplitudes,\n",
    "                source_locations=source_locations,\n",
    "                receiver_locations=receiver_locations,\n",
    "                max_vel=2500,\n",
    "                pml_freq=freq,\n",
    "                time_pad_frac=0.2,\n",
    "            )\n",
    "            out_filt = filt(taper(out[-1]))\n",
    "            loss = 1e6*loss_fn(out_filt, observed_data_filt)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimiser.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc05f9f-7ac2-4f85-b46c-e56d4d234d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "v = model()\n",
    "vmin = v_true.min()\n",
    "vmax = v_true.max()\n",
    "_, ax = plt.subplots(3, figsize=(10.5, 10.5), sharex=True,\n",
    "                     sharey=True)\n",
    "ax[0].imshow(v_init.cpu().T, aspect='auto', cmap='gray',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Initial\")\n",
    "ax[1].imshow(v.detach().cpu().T, aspect='auto', cmap='gray',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Out\")\n",
    "ax[2].imshow(v_true.cpu().T, aspect='auto', cmap='gray',\n",
    "             vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('example_increasing_freq_fwi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3b2d6-8eb6-479a-9a37-261f220231a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
